# SDXL DoRA Trainer

A production-ready tool for fine-tuning Stable Diffusion XL models using **DoRA (Weight-Decomposed Low-Rank Adaptation)**, which is more efficient and effective than traditional LoRA.

## ğŸš¨ Important: Black Image Issue Fixed!

**If you're experiencing black/empty images during generation, see [docs/BLACK_IMAGE_FIX.md](docs/BLACK_IMAGE_FIX.md) for the solution!**

**TL;DR:** Use `--mixed_precision no` instead of `fp16` to fix black image generation with DoRA.

## ğŸš€ Features

- **DoRA Integration**: Uses the latest DoRA technique for more efficient fine-tuning
- **Production Ready**: Robust error handling, logging, and monitoring
- **Memory Optimized**: Support for gradient checkpointing, 8-bit optimizers, and mixed precision
- **Flexible Configuration**: YAML/JSON config files and command-line arguments
- **Multi-GPU Support**: Built on Accelerate for distributed training
- **Comprehensive Logging**: TensorBoard and Weights & Biases integration
- **CLI Tools**: Utilities for dataset analysis and environment checking
- **Cross-Platform**: Works on Windows, Linux, and macOS

## ğŸ“‹ Requirements

- Python 3.8+
- NVIDIA GPU with 12GB+ VRAM (16GB+ recommended for 1024px training)
- CUDA 11.8 or 12.1
- 20GB+ free disk space

## ğŸ› ï¸ Quick Setup

### Option 1: Automated Setup (Recommended)

```bash
# Clone the repository
git clone https://github.com/ElouarnLC/sdxl-dora-trainer.git
cd sdxl-dora-trainer

# Run the automated setup
python setup.py
```

### Option 2: Manual Setup

```bash
# Install PyTorch with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Install other dependencies
pip install -r requirements.txt

# Create directories
mkdir -p output cache logs datasets
```

## ğŸš¦ Quick Start

### 1. Prepare Your Dataset

Organize your training images in a folder structure like this:

```
my_dataset/
â”œâ”€â”€ image1.jpg
â”œâ”€â”€ image1.txt  (caption file)
â”œâ”€â”€ image2.png
â”œâ”€â”€ image2.txt
â””â”€â”€ ...
```

**Caption files are optional** - if not provided, the filename will be used as the caption.

### 2. Check Your Environment

```bash
python utils.py check-env
```

### 3. Analyze Your Dataset

```bash
python scripts/validate_dataset.py --dataset ./my_dataset
```

### 4. Get Training Suggestions

```bash
python utils.py suggest-params --dataset ./my_dataset
```

### 5. Start Training

#### Basic Training
```bash
python sdxl_dora_trainer.py --dataset_path ./my_dataset --output_dir ./output
```

#### Advanced Training with Custom Parameters
```bash
python sdxl_dora_trainer.py \
  --dataset_path ./my_dataset \
  --output_dir ./output \
  --rank 128 \
  --alpha 64 \
  --learning_rate 5e-5 \
  --batch_size 2 \  --max_train_steps 2000 \
  --resolution 1024 \
  --mixed_precision no \
  --report_to wandb \
  --project_name my-sdxl-project
```

#### Using Configuration File
```bash
# Edit config.yaml with your settings
python sdxl_dora_trainer.py --config config.yaml
```

## âš™ï¸ Configuration

### Key Parameters

| Parameter | Description | Default | Recommendations |
|-----------|-------------|---------|-----------------|
| `dataset_path` | Path to training images | Required | Folder with images and captions |
| `rank` | DoRA rank (affects model size) | 64 | 32-128 based on dataset size |
| `alpha` | DoRA alpha parameter | 32 | Usually rank/2 |
| `learning_rate` | Learning rate | 1e-4 | 5e-5 to 2e-4 |
| `batch_size` | Batch size | 1 | Increase based on GPU memory |
| `max_train_steps` | Training steps | 1000 | 500-3000 based on dataset |
| `resolution` | Image resolution | 1024 | 512, 768, or 1024 |
| `mixed_precision` | Precision mode | no | no for stability, bf16 for speed |

### Full Configuration Example

```yaml
# Dataset and Model
dataset_path: "./my_images"
model_name: "stabilityai/stable-diffusion-xl-base-1.0"
output_dir: "./output"

# DoRA Parameters
rank: 128
alpha: 64
dropout: 0.1

# Training
learning_rate: 5e-5
batch_size: 2
gradient_accumulation_steps: 2
max_train_steps: 2000
resolution: 1024

# Memory Optimization
mixed_precision: "no"  # Use "no" for stability, "bf16" for speed
gradient_checkpointing: true
use_8bit_adam: true

# Logging
report_to: "wandb"
project_name: "my-custom-model"
```

## ğŸ”§ Utilities

### Environment Check
```bash
python utils.py check-env
```
Validates your environment, checks GPU memory, and lists system information.

### Dataset Analysis
```bash
python scripts/validate_dataset.py --dataset ./my_images
```
Analyzes your dataset and provides statistics on images, captions, and sizes.

### Parameter Suggestions
```bash
python utils.py suggest-params --dataset ./my_images --gpu-memory 24
```
Suggests optimal training parameters based on your dataset and hardware.

### Configuration Management
```bash
# Create default config
python config_manager.py create --config config.yaml

# Validate config
python config_manager.py validate --config config.yaml
```

## ğŸ“Š Monitoring Training

### TensorBoard (Default)
```bash
tensorboard --logdir ./logs
```

### Weights & Biases
Set `report_to: "wandb"` in your config or use `--report_to wandb`.

### Training Outputs

During training, the tool will:
- Save checkpoints every 250 steps (configurable)
- Generate validation images every 100 steps
- Log training metrics continuously
- Display progress with rich terminal interface

## ğŸ“ Output Structure

After training, your output directory will look like this:

```
output/
â”œâ”€â”€ checkpoints/                    # Model checkpoints
â”‚   â”œâ”€â”€ checkpoint-250/
â”‚   â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â”‚   â””â”€â”€ training_args.bin
â”‚   â”œâ”€â”€ checkpoint-500/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ samples/                        # Validation images
â”‚   â”œâ”€â”€ step_100/
â”‚   â”œâ”€â”€ step_200/
â”‚   â””â”€â”€ ...
â””â”€â”€ final_model/                    # Final trained model
    â”œâ”€â”€ adapter_config.json
    â””â”€â”€ adapter_model.safetensors

logs/
â”œâ”€â”€ tensorboard_logs/               # TensorBoard logs
â””â”€â”€ training.log                    # Text logs
```

## ğŸ¯ DoRA vs LoRA

DoRA (Weight-Decomposed Low-Rank Adaptation) offers several advantages over traditional LoRA:

- **Better Performance**: Higher quality results with the same parameter count
- **More Stable Training**: Less prone to overfitting
- **Improved Convergence**: Faster and more reliable training
- **Better Fine-grained Control**: More precise adaptation to your dataset

## ğŸ’¡ Tips for Better Results

### Dataset Preparation
- Use high-quality images (avoid blurry, low-res, or corrupted images)
- Write descriptive captions that match your target style
- Aim for 50-500 images for most use cases
- Keep aspect ratios consistent when possible

### Training Parameters
- Start with lower rank (32-64) for smaller datasets
- Use higher learning rates (1e-4 to 2e-4) for better convergence
- Increase batch size if you have sufficient GPU memory
- Use longer training for complex datasets

### Memory Optimization
- Enable gradient checkpointing for 40% memory savings
- Use 8-bit Adam optimizer to reduce memory usage
- Use fp16 mixed precision for 2x speedup
- Reduce batch size and increase gradient accumulation steps if OOM

## ğŸ› Troubleshooting

### Common Issues

**Out of Memory (OOM)**
```bash
# Reduce batch size
--batch_size 1 --gradient_accumulation_steps 8

# Enable memory optimizations
--gradient_checkpointing --use_8bit_adam --mixed_precision no

# Use lower resolution
--resolution 768
```

**Black Images During Generation**
See [docs/BLACK_IMAGE_FIX.md](docs/BLACK_IMAGE_FIX.md) for the complete solution.
```bash
# Quick fix: use mixed_precision no
--mixed_precision no
```

**Training Too Slow**
```bash
# Use mixed precision (if stable)
--mixed_precision bf16

# Increase batch size if possible
--batch_size 2

# Use xformers for attention optimization
pip install xformers
```

**Poor Results**
```bash
# Increase training steps
--max_train_steps 2000

# Adjust learning rate
--learning_rate 5e-5

# Use higher rank
--rank 128 --alpha 64
```

**Import Errors**
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall

# Check environment
python utils.py check-env
```

## ğŸ“ Repository Structure

```
sdxl-dora-trainer/
â”œâ”€â”€ ğŸ“„ README.md                    # Main documentation
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â”œâ”€â”€ ğŸ“„ CHANGELOG.md                 # Version history
â”œâ”€â”€ ğŸ“„ pyproject.toml               # Modern Python packaging
â”œâ”€â”€ ğŸ“„ setup.cfg                    # Setup configuration
â”œâ”€â”€ ğŸ“„ requirements.txt             # Production dependencies
â”œâ”€â”€ ğŸ“„ requirements-dev.txt         # Development dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“„ sdxl_dora_trainer.py         # Main training script
â”œâ”€â”€ ğŸ“„ inference.py                 # Inference script
â”œâ”€â”€ ğŸ“„ config_manager.py            # Configuration management
â”œâ”€â”€ ğŸ“„ utils.py                     # Utility functions
â”œâ”€â”€ ğŸ“„ setup.py                     # Automated setup script
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                        # Documentation
â”‚   â”œâ”€â”€ ğŸ“„ BLACK_IMAGE_FIX.md       # âš ï¸ IMPORTANT: Black image fix
â”‚   â”œâ”€â”€ ğŸ“„ INSTALLATION.md          # Installation guide
â”‚   â”œâ”€â”€ ğŸ“„ API.md                   # API reference
â”‚   â””â”€â”€ ğŸ“„ CONTRIBUTING.md          # Contributing guidelines
â”‚
â”œâ”€â”€ ğŸ“‚ examples/                    # Example configurations
â”‚   â”œâ”€â”€ ğŸ“„ basic_config.yaml        # Basic training config
â”‚   â”œâ”€â”€ ğŸ“„ advanced_config.yaml     # Advanced training config
â”‚   â”œâ”€â”€ ğŸ“„ memory_optimized_config.yaml # Low-memory config
â”‚   â”œâ”€â”€ ğŸ“„ train_example.py         # Training example script
â”‚   â””â”€â”€ ğŸ“„ inference_example.py     # Inference example script
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ ğŸ“„ validate_dataset.py      # Dataset validation
â”‚   â”œâ”€â”€ ğŸ“„ debug_dora_weights.py    # Debug DoRA weights
â”‚   â”œâ”€â”€ ğŸ“„ fix_dora_weights.py      # Fix corrupted weights
â”‚   â””â”€â”€ ğŸ“„ batch_train.py           # Batch training script
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                       # Test suite
â”‚   â”œâ”€â”€ ğŸ“„ test_setup.py            # Setup tests
â”‚   â”œâ”€â”€ ğŸ“„ test_device_allocation.py # GPU tests
â”‚   â”œâ”€â”€ ğŸ“„ test_sdxl_simple.py      # SDXL tests
â”‚   â””â”€â”€ ğŸ“„ test_vae_encoding.py     # VAE tests
â”‚
â””â”€â”€ ğŸ“‚ .github/                     # GitHub specific files
    â”œâ”€â”€ ğŸ“‚ ISSUE_TEMPLATE/
    â”‚   â”œâ”€â”€ ğŸ“„ bug_report.md
    â”‚   â””â”€â”€ ğŸ“„ feature_request.md
    â””â”€â”€ ğŸ“„ pull_request_template.md
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Setup
```bash
git clone https://github.com/ElouarnLC/sdxl-dora-trainer.git
cd sdxl-dora-trainer
pip install -r requirements.txt
pip install -e .
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Diffusers](https://github.com/huggingface/diffusers) - The foundation for stable diffusion training
- [PEFT](https://github.com/huggingface/peft) - DoRA implementation
- [Accelerate](https://github.com/huggingface/accelerate) - Distributed training support
- [Rich](https://github.com/Textualize/rich) - Beautiful terminal interface

## ğŸ“š Citation

If you use this tool in your research, please cite:

```bibtex
@software{sdxl_dora_trainer,
  title={SDXL DoRA Trainer: Production-Ready Fine-tuning Tool},
  author={ElouarnLC},
  year={2025},
  url={https://github.com/ElouarnLC/sdxl-dora-trainer},
  license={MIT}
}
```

---

**Happy Training! ğŸ¨âœ¨**
