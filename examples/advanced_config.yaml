# Advanced Configuration for High-End Training
# For users with powerful GPUs and larger datasets

# Dataset and Model Configuration
dataset_path: "./large_dataset"
model_name: "stabilityai/stable-diffusion-xl-base-1.0"
output_dir: "./output"
cache_dir: "./cache"

# DoRA Parameters (Higher rank for complex datasets)
rank: 128               # Higher rank for larger datasets
alpha: 64               # Usually rank/2
dropout: 0.1
target_modules:
  - "to_k"
  - "to_q"
  - "to_v" 
  - "to_out.0"
  - "proj_in"
  - "proj_out"
  - "ff.net.0.proj"
  - "ff.net.2"

# Training Parameters
learning_rate: 1e-4     # Higher learning rate for faster convergence
batch_size: 4           # Larger batch size for stability
gradient_accumulation_steps: 2
max_train_steps: 3000   # Longer training for complex datasets
warmup_steps: 200
save_every: 500
validation_steps: 200

# Image Parameters
resolution: 1024
center_crop: true
random_flip: true

# Optimization
optimizer: "adamw"
weight_decay: 0.01
beta1: 0.9
beta2: 0.999
epsilon: 1e-8
max_grad_norm: 1.0

# Scheduler
lr_scheduler: "cosine"
lr_warmup_steps: 200

# Memory and Performance
mixed_precision: "bf16"  # Use bf16 for speed if you have Ampere+ GPU
gradient_checkpointing: true
use_8bit_adam: true

# Logging and Monitoring
logging_dir: "./logs"
log_level: "INFO"
report_to: "wandb"       # Use wandb for advanced tracking
project_name: "advanced-sdxl-training"
run_name: "high-rank-experiment"

# Validation
validation_prompts:
  - "a photorealistic portrait"
  - "a detailed landscape painting"
  - "an artistic still life"
  - "a futuristic cityscape"
  - "a fantasy creature"

# Advanced Options
seed: 42
debug: false
resume_from_checkpoint: null
